language: python

jdk:
  - openjdk7

env:
  matrix:
    - SPARK_VERSION="1.4.1" PYTHON_VERSION="2.7"
    - SPARK_VERSION="1.4.1" PYTHON_VERSION="3.4"
    - SPARK_VERSION="1.5.2" PYTHON_VERSION="2.7"
    - SPARK_VERSION="1.5.2" PYTHON_VERSION="3.4"
    - SPARK_VERSION="1.6.0" PYTHON_VERSION="2.7"
    - SPARK_VERSION="1.6.0" PYTHON_VERSION="3.4"

before_install:
  - sudo apt-get update
  - if [[ "$SPARK_VERSION" == "1.6.0" ]]; then
      wget http://d3kbcqa49mib13.cloudfront.net/spark-1.6.0-bin-hadoop2.6.tgz;
    elif [[ "$SPARK_VERSION" == "1.5.2" ]]; then
      wget http://d3kbcqa49mib13.cloudfront.net/spark-1.5.2-bin-hadoop2.6.tgz;
    else
      wget http://d3kbcqa49mib13.cloudfront.net/spark-1.4.1-bin-hadoop2.6.tgz;
    fi
  - if [[ "$PYTHON_VERSION" == "2.7" ]]; then
      wget http://repo.continuum.io/miniconda/Miniconda2-3.19.0-Linux-x86_64.sh -O miniconda.sh;
    else
      wget http://repo.continuum.io/miniconda/Miniconda3-3.19.0-Linux-x86_64.sh -O miniconda.sh;
    fi
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - hash -r
  - conda config --set always_yes yes --set changeps1 no
  - conda update -q conda
  - conda info -a

install:
  - conda create --yes -q -n test-environment python=$PYTHON_VERSION nose numpy
    scipy scikit-learn
  - source activate test-environment
  - pip install -r requirements.txt
  - pip install rednose
  - tar -xzvf spark-${SPARK_VERSION}-bin-hadoop2.6.tgz && export SPARK_HOME=`pwd`/spark-${SPARK_VERSION}-bin-hadoop2.6;
  - sudo rm -rf /dev/shm && sudo ln -s /run/shm /dev/shm

script:
  - "./runtests.sh"

notifications:
  hipchat:
    rooms:
      secure: aLwgryE6o1TzwbCu9zaf6XdtQS7u7VZv7C5HY8zcpUgNBLmPUTJax/WgU3n259P4YRdHitpdgUPZeeCOY7hcOBC9uztfbE6ChI0A8fnz3ClWnOsKdo+sqFa29Jy+2KMcABxsLweLnMyJeVJdOO9o0Z9U3CKF+6iir/WCzVa7Ln0=
