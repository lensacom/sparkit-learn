language: python

jdk:
  - openjdk7

env:
  matrix:
    - SPARK_VERSION="1.3.1" PYTHON_VERSION="2.7"
    - SPARK_VERSION="1.4.0" PYTHON_VERSION="2.7"
    - SPARK_VERSION="1.4.0" PYTHON_VERSION="3.4"

before_install:
  - sudo apt-get update
  - if [[ "$SPARK_VERSION" == "1.3.1" ]]; then
      wget http://d3kbcqa49mib13.cloudfront.net/spark-1.3.1-bin-hadoop2.4.tgz;
    else
      wget http://d3kbcqa49mib13.cloudfront.net/spark-1.4.0-bin-hadoop2.6.tgz;
    fi
  - if [[ "$PYTHON_VERSION" == "2.7" ]]; then
      wget http://repo.continuum.io/miniconda/Miniconda-3.7.3-Linux-x86_64.sh -O miniconda.sh;
    else
      wget http://repo.continuum.io/miniconda/Miniconda3-3.7.3-Linux-x86_64.sh -O miniconda.sh;
    fi
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - hash -r
  - conda config --set always_yes yes --set changeps1 no
  - conda update -q conda
  - conda info -a

install:
  - conda create --yes -q -n test-environment python=$PYTHON_VERSION nose numpy
    scipy scikit-learn
  - source activate test-environment
  - pip install -r requirements.txt
  - pip install rednose
  - if [[ "$SPARK_VERSION" == "1.3.1" ]]; then
      tar -xzf spark-1.3.1-bin-hadoop2.4.tgz;
      export SPARK_HOME=`pwd`/spark-1.3.1-bin-hadoop2.4;
    else
      tar -xzf spark-1.4.0-bin-hadoop2.6.tgz;
      export SPARK_HOME=`pwd`/spark-1.4.0-bin-hadoop2.6;
    fi
  - sudo rm -rf /dev/shm && sudo ln -s /run/shm /dev/shm

script:
  - "./runtests.sh"

notifications:
  hipchat:
    rooms:
      secure: aLwgryE6o1TzwbCu9zaf6XdtQS7u7VZv7C5HY8zcpUgNBLmPUTJax/WgU3n259P4YRdHitpdgUPZeeCOY7hcOBC9uztfbE6ChI0A8fnz3ClWnOsKdo+sqFa29Jy+2KMcABxsLweLnMyJeVJdOO9o0Z9U3CKF+6iir/WCzVa7Ln0=
